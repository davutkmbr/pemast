import type { ProcessedMessage } from './types.js';

export class ResponseFormatter {
  formatResponse(processedMessage: ProcessedMessage): string {
    const { type, text, metadata } = processedMessage;
    
    switch (type) {
      case 'text':
        return `ğŸ“ **Message received:** "${text}"`;
      
      case 'voice':
        // Check if it was processed by transcript processor
        if (metadata.processingInfo?.processor === 'transcript') {
          if (metadata.processingInfo.error) {
            return `ğŸ¤ **Voice message received** (${metadata.processingInfo.duration || 'unknown'}s)\n` +
                   `âŒ Transcription failed: ${metadata.processingInfo.error}\n\n` +
                   `I received your voice message but couldn't transcribe it. Please try again or send a text message.`;
          } else {
            return `ğŸ¤ **Voice message transcribed** (${metadata.processingInfo.duration || 'unknown'}s):\n\n` +
                   `"${text}"\n\n` +
                   `âœ… Successfully processed using OpenAI Whisper`;
          }
        } else {
          return `ğŸ¤ Voice message received (${metadata.fileSize ? Math.round(metadata.fileSize / 1024) + 'KB' : 'unknown size'}). Transcription will be implemented soon!`;
        }
      
      case 'document':
        return `ğŸ“„ **Document received:** "${metadata.fileName}" (${metadata.fileSize ? Math.round(metadata.fileSize / 1024) + 'KB' : 'unknown size'})\n\n` +
               `Document analysis will be implemented soon!`;
      
      case 'photo':
        return `ğŸ“¸ **Photo received** (${metadata.fileSize ? Math.round(metadata.fileSize / 1024) + 'KB' : 'unknown size'})\n\n` +
               `Image analysis will be implemented soon!`;
      
      default:
        return `â“ **Unknown message type:** "${text}"`;
    }
  }
} 